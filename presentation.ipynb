{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ тональности русскоязычных комментариев Stepik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## NLP\n",
    "\n",
    "Обработка естественного языка (Natural Language Processing, NLP) - направление ИИ и мат. лингвистики для анализа и синтеза естественного языка.\n",
    "\n",
    "Применяется для:\n",
    "1. Информационный поиск \n",
    "1. Извлечение информации\n",
    "1. Генерация текста (Чатботы, переводчики)\n",
    "1. Распознования речи\n",
    "1. Синтез речи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Какую информацию можно извлечь из текста?\n",
    "\n",
    "В общем смысле текст - это семантика и синтаксис.\n",
    "\n",
    "Синтаксис - то из чего состоит текст:\n",
    "1. Слова\n",
    "1. Написание\n",
    "1. Части речи\n",
    "1. Предложения\n",
    "\n",
    "Семантика - смысл в этом тексте:\n",
    "1. Смысл слов\n",
    "1. Распознование именнованых сущностей (NER) \n",
    "1. Извлечение связей\n",
    "1. Определение темы текста\n",
    "1. Анализ тональности \n",
    "1. И многое другое\n",
    "\n",
    "Извлечение - это разделение и классификация всего текста или его частей.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ тональности\n",
    "\n",
    "Анализ тональности (Sentiment analysis, Opinion mining) - это область NLP, которая занимается изучением мнений и эмоций.\n",
    "\n",
    "Где применяется:\n",
    "1. Маркетинг\n",
    "2. Социологические исследования\n",
    "3. Политика\n",
    "\n",
    "Как это работает\n",
    "\n",
    "\n",
    "![Image alt](images/sent_analyze1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Словарь слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pos = \"Котики — это не только мягкий мех, но и три — четыре килограмма фантастического позитива ^_^ :))))\"\n",
    "text_neg = \"Это был ужасный фильм\"\n",
    "\n",
    "dictionary_pos = {  \n",
    "    \n",
    "    'Котики' : 0.5,\n",
    "    'позитива' : 0.9,\n",
    "    'мягкий' : 0.3\n",
    "    \n",
    "}\n",
    "\n",
    "dictionary_neg = {  \n",
    "    \n",
    "    'ужасный' : -1.0,   \n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Котики',\n",
       " '—',\n",
       " 'это',\n",
       " 'не',\n",
       " 'только',\n",
       " 'мягкий',\n",
       " 'мех,',\n",
       " 'но',\n",
       " 'и',\n",
       " 'три',\n",
       " '—',\n",
       " 'четыре',\n",
       " 'килограмма',\n",
       " 'фантастического',\n",
       " 'позитива',\n",
       " '^_^',\n",
       " ':))))']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pos.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "\n",
    "for word in text_pos.split(' '):\n",
    "    score += dictionary_neg.get(word, 0)\n",
    "    score += dictionary_pos.get(word, 0)\n",
    "\n",
    "if score > 0:\n",
    "    print('pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK\n",
    "\n",
    "NLTK (Natural Language Toolkit) - пакет библиотек для обработки естественного языка, например для токенизации, стематизации, распозновании именованых сущностей и многого другого."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Котики',\n",
       " '—',\n",
       " 'это',\n",
       " 'не',\n",
       " 'только',\n",
       " 'мягкий',\n",
       " 'мех',\n",
       " ',',\n",
       " 'но',\n",
       " 'и',\n",
       " 'три',\n",
       " '—',\n",
       " 'четыре',\n",
       " 'килограмма',\n",
       " 'фантастического',\n",
       " 'позитива',\n",
       " '^',\n",
       " '_',\n",
       " '^',\n",
       " ':)',\n",
       " ')',\n",
       " ')']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "tokenizer.tokenize(text_pos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "котик\n",
      "—\n",
      "эт\n",
      "не\n",
      "тольк\n",
      "мягк\n",
      "мех\n",
      ",\n",
      "но\n",
      "и\n",
      "три\n",
      "—\n",
      "четыр\n",
      "килограмм\n",
      "фантастическ\n",
      "позитив\n",
      "^\n",
      "_\n",
      "^\n",
      ":)\n",
      ")\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import RussianStemmer\n",
    "\n",
    "stemer = RussianStemmer()\n",
    "\n",
    "for token in tokenizer.tokenize(text_pos):\n",
    "    print(stemer.stem(token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "POSITIVE_COMMENTS_CSV = 'datasets/comment_neg.csv'\n",
    "NEGATIVE_COMMENTS_CSV = 'datasets/comment_pos.csv'\n",
    "\n",
    "negative_comments = pd.read_csv(\n",
    "    POSITIVE_COMMENTS_CSV, dialect='excel-tab')['text']\n",
    "positive_comments = pd.read_csv(\n",
    "    NEGATIVE_COMMENTS_CSV, dialect='excel-tab')['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>АНДРЮХА РЕСПЕКТ !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</p>'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_comments[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Roman_Kalganov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'андрюха респект'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'@[a-zA-Zа-яА-Я]*[_[a-zA-Zа-яА-Я]*]*', '', text)    \n",
    "    text = re.sub(r'[^а-яА-Я ]', '', text)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'http', '', text)\n",
    "    text = re.sub(r'@\\S+', '', text)\n",
    "    text = re.sub(r'(<(/?[^>]+)>)', '', text)\n",
    "    text = re.sub(r'[-.?!)(,:]', '', text)\n",
    "    \n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "    \n",
    "    text = \" \".join(tokens)\n",
    "    \n",
    "    return text\n",
    "\n",
    "preprocess_text(positive_comments[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in positive_comments.items():\n",
    "    positive_comments[index] = preprocess_text(row)\n",
    "    \n",
    "for index, row in negative_comments.items():\n",
    "    negative_comments[index] = preprocess_text(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        кстати благодаря этому начала активную экодеят...\n",
       "1        приглашаем официальные лица готовим ролики заг...\n",
       "2        запрос углубленное изучение технологий комьюни...\n",
       "3        почемуто сразу ночлежка вспоминается любой про...\n",
       "4        протяжении истории численность населения регул...\n",
       "5        плюс сила положительного примера люди воспольз...\n",
       "6        рр предназначен горячей воды числе пищевых про...\n",
       "7        рекомендую алика главное отличие конкурентов б...\n",
       "8        верифицируемостьто лгкая крайней мере абсолютн...\n",
       "9        просто экологичны заставляют людей полюбить пр...\n",
       "10       наверное стать экспертами создать имидж экспер...\n",
       "11                                         андрюха респект\n",
       "12       спасибо команде курса выкладку обобщенного ана...\n",
       "13       организации взгляд команду несколько отличаетс...\n",
       "14            пожалуйста лично рад помочь нуждается помощи\n",
       "15       бизнеса получается привлекать небольшие суммы ...\n",
       "16       очень интересно читать творческие задания итог...\n",
       "17                                 проспорил преподавателю\n",
       "18                        используйте тело цикла получится\n",
       "19                                                        \n",
       "20                                                        \n",
       "21       хочется поблагодарить участников активную деят...\n",
       "22       продаже видела вконтакте группе сделать быстры...\n",
       "23       относительно просроченных лекарств группе точк...\n",
       "24       виды рассылокинформационные уведомления ден оп...\n",
       "25       маркетинг стратетегия взаимодействия общю помо...\n",
       "26                                                        \n",
       "27       итогам проверенных мною творческих заданий хоч...\n",
       "28       дедлайн это термин принятый системой всплывает...\n",
       "29       модуле поговорим экологичный быт выбирать экол...\n",
       "                               ...                        \n",
       "18549      павел павел хочет написать программу писать нам\n",
       "18550    задача легкая слегка запутать условие читайте ...\n",
       "18551                                  оператор вывода это\n",
       "18552    допустим нод это значит делится нацело делится...\n",
       "18553    класса вызван конструктор одного аргумента нея...\n",
       "18554    это сравнить среднюю зп медианную зп стране ре...\n",
       "18555                                  нафига эта угадайка\n",
       "18556    решил этим способом потратил около часадвух вы...\n",
       "18557    раза получилось читайте внимательно логично пр...\n",
       "18558    удобно написать просто имя библиотеки например...\n",
       "18559               кажется ответе тест опечаткатам должно\n",
       "18560                     понял читать доки вся инфа видео\n",
       "18561    хороший курс спасибо отчаянно хватало темы ука...\n",
       "18562                                                     \n",
       "18563    решил перебрав множество вариантов разрисовав ...\n",
       "18564    имеется ввиду расстояние точкой прямой расстоя...\n",
       "18565    всякий случай пишу текущий момент ссылки работают\n",
       "18566                            шутка темунедосказанность\n",
       "18567    лекции это сказано примерно сортировки должен ...\n",
       "18568                   кстати ке нативный терминал убунты\n",
       "18569    вижу онлайнкалькуляторе строите добавляя слой ...\n",
       "18570         ошиблись знаком возведении четвертую степень\n",
       "18571                                                торта\n",
       "18572    интересно году бытовые приборы которые использ...\n",
       "18573    полностью согласен распарсить словарь родитель...\n",
       "18574             кажется система принимает неверный ответ\n",
       "18575    стоит формулировать задачу понимания условия п...\n",
       "18576    парни день втуплял значит увеличивает значение...\n",
       "18577    сумме хи квадрат учитываются зависимые переменные\n",
       "18578    мыто знаем время постановку диагноза доктором ...\n",
       "Name: text, Length: 18579, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формируем словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "stem_count = Counter()\n",
    "\n",
    "def count_unique_tokens_in_comments(comments):\n",
    "    for _, row in comments.items():                \n",
    "        for token in  tokenizer.tokenize(row):            \n",
    "            stem_count[stemer.stem(token)] += 1\n",
    "\n",
    "\n",
    "count_unique_tokens_in_comments(positive_comments)\n",
    "count_unique_tokens_in_comments(negative_comments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27509"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stem_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 5000\n",
    "\n",
    "vocab = sorted(stem_count, key=stem_count.get, reverse=True)[:VOCAB_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['эт',\n",
       " 'котор',\n",
       " 'курс',\n",
       " 'задач',\n",
       " 'нужн',\n",
       " 'так',\n",
       " 'прост',\n",
       " 'решен',\n",
       " 'ответ',\n",
       " 'дан',\n",
       " 'задан',\n",
       " 'числ',\n",
       " 'сам',\n",
       " 'строк',\n",
       " 'очен',\n",
       " 'одн',\n",
       " 'функц',\n",
       " 'перв',\n",
       " 'значен',\n",
       " 'код',\n",
       " 'работа',\n",
       " 'друг',\n",
       " 'получ',\n",
       " 'вопрос',\n",
       " 'сво',\n",
       " 'пример',\n",
       " 'тест',\n",
       " 'поня',\n",
       " 'перемен',\n",
       " 'реш',\n",
       " 'правильн',\n",
       " 'услов',\n",
       " 'сдела',\n",
       " 'случа',\n",
       " 'спасиб',\n",
       " 'дела',\n",
       " 'программ',\n",
       " 'кажд',\n",
       " 'ваш',\n",
       " 'должн',\n",
       " 'метод',\n",
       " 'поч',\n",
       " 'ошибк',\n",
       " 'наш',\n",
       " 'вывод',\n",
       " 'написа',\n",
       " 'комментар',\n",
       " 'класс',\n",
       " 'говор',\n",
       " 'работ',\n",
       " 'вариант',\n",
       " 'возможн',\n",
       " 'вс',\n",
       " 'элемент',\n",
       " 'те',\n",
       " 'цикл',\n",
       " 'тип',\n",
       " 'например',\n",
       " 'слов',\n",
       " 'получа',\n",
       " 'файл',\n",
       " 'виде',\n",
       " 'люд',\n",
       " 'вообщ',\n",
       " 'помощ',\n",
       " 'использова',\n",
       " 'част',\n",
       " 'имен',\n",
       " 'дел',\n",
       " 'хот',\n",
       " 'объект',\n",
       " 'результат',\n",
       " 'урок',\n",
       " 'понима',\n",
       " 'понятн',\n",
       " 'проект',\n",
       " 'нов',\n",
       " 'след',\n",
       " 'количеств',\n",
       " 'люб',\n",
       " 'вид',\n",
       " 'втор',\n",
       " 'язык',\n",
       " 'как',\n",
       " 'интересн',\n",
       " 'чита',\n",
       " 'врем',\n",
       " 'цел',\n",
       " 'реша',\n",
       " 'ссылк',\n",
       " 'больш',\n",
       " 'равн',\n",
       " 'поэт',\n",
       " 'сложн',\n",
       " 'команд',\n",
       " 'счита',\n",
       " 'явля',\n",
       " 'дума',\n",
       " 'начина',\n",
       " 'сраз']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторизуем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'кстати благодаря этому начала активную экодеятельность году побывала риме жила местного сервис молодого человека раздельный сбор квартире приезду стала узнавать возможности спб'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'андрюх': True, 'респект': True}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def comment_to_feachures(comment):\n",
    "    vector = []\n",
    "    for token in tokenizer.tokenize(comment):\n",
    "        stem = stemer.stem(token)        \n",
    "        if stem:\n",
    "            vector.append(stem)        \n",
    "    return dict([(w, True) for w in vector])\n",
    "\n",
    "comment_to_feachures(positive_comments[11])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown token: ь\n",
      "Unknown token: ь\n"
     ]
    }
   ],
   "source": [
    "comments = []\n",
    "\n",
    "neg_comments = []\n",
    "pos_comments = []\n",
    "\n",
    "for ii, (_, comment) in enumerate(negative_comments.items()):\n",
    "    comments.append(comment)\n",
    "    neg_comments.append((comment_to_feachures(comment), 'neg'))\n",
    "for ii, (_, comment) in enumerate(positive_comments.items()):\n",
    "    comments.append(comment)\n",
    "    pos_comments.append((comment_to_feachures(comment), 'pos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тренируем классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 15813 instances, test on 5272 instances\n"
     ]
    }
   ],
   "source": [
    "negcutoff = len(neg_comments) * 3 / 4\n",
    "poscutoff = len(pos_comments) * 3 / 4\n",
    "\n",
    "trainfeats = neg_comments[:int(negcutoff)] + pos_comments[:int(poscutoff)]\n",
    "testfeats = neg_comments[int(negcutoff):] + pos_comments[int(poscutoff):]\n",
    "\n",
    "print('train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_classifier = NaiveBayesClassifier.train(trainfeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8710166919575114\n",
      "Most Informative Features\n",
      "            медиаграмотн = True              neg : pos    =     98.5 : 1.0\n",
      "                  послан = True              neg : pos    =     76.6 : 1.0\n",
      "             журналистик = True              neg : pos    =     76.6 : 1.0\n",
      "                   вернм = True              neg : pos    =     76.6 : 1.0\n",
      "                    нест = True              neg : pos    =     62.7 : 1.0\n",
      "                     тих = True              neg : pos    =     47.9 : 1.0\n",
      "                    фигн = True              neg : pos    =     38.6 : 1.0\n",
      "                   мужик = True              neg : pos    =     33.5 : 1.0\n",
      "                  диалог = True              neg : pos    =     30.0 : 1.0\n",
      "                     мим = True              neg : pos    =     28.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print('accuracy:', nltk.classify.util.accuracy(comments_classifier, testfeats))\n",
    "comments_classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8810698027314112\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_classifier = SklearnClassifier(SVC()).train(trainfeats)\n",
    "\n",
    "\n",
    "print('accuracy:', nltk.classify.util.accuracy(svm_classifier, testfeats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификатор на другом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "saved_model = open('models/tweet_model.pickle', 'rb')\n",
    "\n",
    "loaded_classifier = pickle.load(saved_model)\n",
    "\n",
    "saved_model.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7092185128983308\n",
      "Most Informative Features\n",
      "                 царевич = True              pos : neg    =     78.9 : 1.0\n",
      "                 шумахер = True              neg : pos    =     35.2 : 1.0\n",
      "                калашник = True              neg : pos    =     28.4 : 1.0\n",
      "                  погибл = True              neg : pos    =     28.4 : 1.0\n",
      "                 позитив = True              pos : neg    =     26.8 : 1.0\n",
      "            соболезнован = True              neg : pos    =     26.1 : 1.0\n",
      "                  сконча = True              neg : pos    =     22.2 : 1.0\n",
      "                  сметан = True              pos : neg    =     21.1 : 1.0\n",
      "                 почемуу = True              neg : pos    =     19.5 : 1.0\n",
      "                 пичальк = True              neg : pos    =     19.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print('accuracy:', nltk.classify.util.accuracy(loaded_classifier, testfeats))\n",
    "loaded_classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
