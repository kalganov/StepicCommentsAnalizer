{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import nltk.classify.util\n",
    "import pandas as pd\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "POSITIVE_TWEETS_CSV = 'datasets/negative.csv'\n",
    "NEGATIVE_TWEETS_CSV = 'datasets/positive.csv'\n",
    "\n",
    "\n",
    "\n",
    "VOCAB_SIZE = 5000\n",
    "\n",
    "tweets_col_number = 3\n",
    "\n",
    "negative_tweets = pd.read_csv(\n",
    "    POSITIVE_TWEETS_CSV, header=None, delimiter=';')[[tweets_col_number]]\n",
    "positive_tweets = pd.read_csv(\n",
    "    NEGATIVE_TWEETS_CSV, header=None, delimiter=';')[[tweets_col_number]]\n",
    "\n",
    "stemer = RussianStemmer()\n",
    "regex = re.compile('[^а-яА-Я ]')\n",
    "stem_cache = {}\n",
    "\n",
    "\n",
    "def get_stem(token):\n",
    "    stem = stem_cache.get(token, None)\n",
    "    if stem:\n",
    "        return stem\n",
    "    token = regex.sub('', token).lower()\n",
    "    stem = stemer.stem(token)\n",
    "    stem_cache[token] = stem\n",
    "    return stem\n",
    "\n",
    "\n",
    "stem_count = Counter()\n",
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true,
    "_uuid": "de919ca891d76cad117e814eee7ac32a07c7789a"
   },
   "outputs": [],
   "source": [
    "def count_unique_tokens_in_tweets(tweets):\n",
    "    for _, tweet_series in tweets.iterrows():\n",
    "        tweet = tweet_series[3]\n",
    "        tokens = tokenizer.tokenize(tweet)\n",
    "        for token in tokens:\n",
    "            stem = get_stem(token)\n",
    "            stem_count[stem] += 1\n",
    "\n",
    "\n",
    "count_unique_tokens_in_tweets(negative_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true,
    "_uuid": "563d7b37aaf814f82a695037a9cd7dc61c2bef3e"
   },
   "outputs": [],
   "source": [
    "count_unique_tokens_in_tweets(positive_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true,
    "_uuid": "d2ec6fe2ae6d4273bc27189f901a3a01e49d4ca4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique stems found:  91780\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique stems found: \", len(stem_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true,
    "_uuid": "202bb68784d11ee273ef3578ace63a2a97db11f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'не', 'я', 'и', 'в', 'на', 'а', 'что', 'так', 'с', 'эт', 'как', 'у', 'мен', 'мне', 'все', 'но', 'он', 'ты', 'теб', 'ну', 'мо', 'то', 'уж', 'по', 'был', 'ещ', 'за', 'да', 'вот', 'же', 'тольк', 'нет', 'сегодн', 'о', 'прост', 'бы', 'над', 'когд', 'хоч', 'очен', 'к', 'сам', 'ден', 'будет', 'мы', 'от', 'хорош', 'из', 'есл', 'тепер', 'тож', 'буд', 'сво', 'год', 'даж', 'завтр', 'нов', 'дом', 'до', 'там', 'ест', 'вообщ', 'ег', 'вс', 'дела', 'пот', 'одн', 'для', 'больш', 'хот', 'спасиб', 'мог', 'сейчас', 'е', 'себ', 'нас', 'блин', 'раз', 'кто', 'дума', 'утр', 'котор', 'любл', 'поч', 'зна', 'говор', 'лучш', 'нич', 'без', 'ил', 'вы', 'друг', 'тут', 'чтоб', 'всем', 'бол', 'люд', 'сдела', 'сказа']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(stem_count, key=stem_count.get, reverse=True)[:VOCAB_SIZE]\n",
    "print(vocab[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true,
    "_uuid": "af1d9d3269fe7f267765d2acf1323bf4dcae4153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stem: я, count: 66045\n99\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "print(\"stem: {}, count: {}\"\n",
    "      .format(vocab[idx], stem_count.get(vocab[idx])))\n",
    "\n",
    "token_2_idx = {vocab[i]: i for i in range(VOCAB_SIZE)}\n",
    "len(token_2_idx)\n",
    "\n",
    "print(token_2_idx['сказа'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true,
    "_uuid": "3e842a3899be3f7742d526d493006c27f5867450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet: Коллеги сидят рубятся в Urban terror, а я из-за долбанной винды не могу :(\ntweet_to_feachure: {'contains-word(коллег)': True, 'contains-word(сид)': True, 'contains-word(руб)': True, 'contains-word(в)': True, 'contains-word(а)': True, 'contains-word(я)': True, 'contains-word(изз)': True, 'contains-word(долба)': True, 'contains-word(винд)': True, 'contains-word(не)': True, 'contains-word(мог)': True}\nна\n"
     ]
    }
   ],
   "source": [
    "def tweet_to_feachure(tweet, show_unknowns=False):\n",
    "    vector = []\n",
    "    for token in tokenizer.tokenize(tweet):\n",
    "        stem = get_stem(token)        \n",
    "        if stem:\n",
    "            vector.append(stem)\n",
    "        elif show_unknowns:\n",
    "            print(\"Unknown token: {}\".format(token))\n",
    "    return dict([('contains-word(%s)' % w, True) for w in vector])\n",
    "\n",
    "\n",
    "tweet = negative_tweets.iloc[1][3]\n",
    "print(\"tweet: {}\".format(tweet))\n",
    "print(\"tweet_to_feachure: {}\".format(tweet_to_feachure(tweet)))\n",
    "print(vocab[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true,
    "scrolled": true,
    "_uuid": "a1415501310447b8c29b0a506d7eb0b421d2407e"
   },
   "outputs": [],
   "source": [
    "tweets = []\n",
    "\n",
    "neg_tweets = []\n",
    "pos_tweets = []\n",
    "\n",
    "for ii, (_, tweet) in enumerate(negative_tweets.iterrows()):\n",
    "    tweets.append(tweet[3])\n",
    "    neg_tweets.append((tweet_to_feachure(tweet[3]),'neg'))\n",
    "for ii, (_, tweet) in enumerate(positive_tweets.iterrows()):\n",
    "    tweets.append(tweet[3])\n",
    "    pos_tweets.append((tweet_to_feachure(tweet[3]),'pos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "trusted": true,
    "_uuid": "3b6b47611fd33a8e90e2785154da09d6c3bd338b"
   },
   "outputs": [],
   "source": [
    "print(pos_tweets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "trusted": true,
    "_uuid": "b530e2bf911aa88cc25879a3adaa1b7e348b5b2a"
   },
   "outputs": [],
   "source": [
    "negcutoff = len(neg_tweets) * 3 / 4\n",
    "poscutoff = len(pos_tweets) * 3 / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "trusted": true,
    "_uuid": "f2b15869a4f635fd47279696c844e04d35bdb55f"
   },
   "outputs": [],
   "source": [
    "trainfeats = neg_tweets[:int(negcutoff)] + pos_tweets[:int(poscutoff)]\n",
    "testfeats = neg_tweets[int(negcutoff):] + pos_tweets[int(poscutoff):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "trusted": true,
    "_uuid": "2503d04f0b3dc04adecea96378ff0c0e69a31012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 170125 instances, test on 56709 instances\n"
     ]
    }
   ],
   "source": [
    "print('train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "trusted": true,
    "_uuid": "401bfb84de43208eef3d2661a324178e1604d1bf"
   },
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier.train(trainfeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "trusted": true,
    "_uuid": "45f93ccee12e34c9e76a72b6bba0c58d8e858b54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7102047294080305\nMost Informative Features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  contains-word(царевич) = True              pos : neg    =     78.9 : 1.0\n  contains-word(шумахер) = True              neg : pos    =     35.2 : 1.0\n   contains-word(погибл) = True              neg : pos    =     28.4 : 1.0\n contains-word(калашник) = True              neg : pos    =     28.4 : 1.0\n  contains-word(позитив) = True              pos : neg    =     26.8 : 1.0\ncontains-word(соболезнован) = True              neg : pos    =     26.1 : 1.0\n   contains-word(сконча) = True              neg : pos    =     22.2 : 1.0\n   contains-word(сметан) = True              pos : neg    =     21.1 : 1.0\n   contains-word(ублюдк) = True              neg : pos    =     19.5 : 1.0\n  contains-word(пичальк) = True              neg : pos    =     19.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print('accuracy:', nltk.classify.util.accuracy(classifier, testfeats))\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "trusted": true,
    "_uuid": "3603a5af7adc4488364beee19eae0168c724db78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'contains-word(плох)': True,\n  'contains-word(у)': True,\n  'contains-word(мен)': True,\n  'contains-word(сейчас)': True,\n  'contains-word(по)': True,\n  'contains-word(втор)': True,\n  'contains-word(круг)': True,\n  'contains-word(так)': True,\n  'contains-word(как)': True,\n  'contains-word(не)': True,\n  'contains-word(долеч)': True,\n  'contains-word(в)': True,\n  'contains-word(прошл)': True,\n  'contains-word(раз)': True,\n  'contains-word(аккуратн)': True},\n 'neg')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testfeats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_train = open('models/tweet_model_train_features.pickle', 'wb')\n",
    "pickle.dump(trainfeats,model_train)\n",
    "model_train.close()\n",
    "model_test = open('models/tweet_model_test_features.pickle', 'wb')\n",
    "pickle.dump(testfeats,model_test)\n",
    "model_test.close()\n",
    "\n",
    "# model = open('models/tweet_model.pickle', 'wb')\n",
    "# \n",
    "# pickle.dump(classifier,model)\n",
    "# \n",
    "# model.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7102047294080305\nMost Informative Features\n  contains-word(царевич) = True              pos : neg    =     78.9 : 1.0\n  contains-word(шумахер) = True              neg : pos    =     35.2 : 1.0\n contains-word(калашник) = True              neg : pos    =     28.4 : 1.0\n   contains-word(погибл) = True              neg : pos    =     28.4 : 1.0\n  contains-word(позитив) = True              pos : neg    =     26.8 : 1.0\ncontains-word(соболезнован) = True              neg : pos    =     26.1 : 1.0\n   contains-word(сконча) = True              neg : pos    =     22.2 : 1.0\n   contains-word(сметан) = True              pos : neg    =     21.1 : 1.0\n   contains-word(ублюдк) = True              neg : pos    =     19.5 : 1.0\n  contains-word(почемуу) = True              neg : pos    =     19.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "saved_model = open('models/tweet_model.pickle', 'rb')\n",
    "\n",
    "loaded_classifier = pickle.load(saved_model)\n",
    "\n",
    "saved_model.close()\n",
    "\n",
    "print('accuracy:', nltk.classify.util.accuracy(loaded_classifier, testfeats))\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
